{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc14e4bb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9db749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "\n",
    "import spacy \n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['PWD'],'scripts'))\n",
    "\n",
    "from scrap import get_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779d628",
   "metadata": {},
   "source": [
    "## Collect comments for January 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593bd223-1715-42df-a80b-34b9e2ac73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data unpickled successfully!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.environ['PWD'],'data/january_comments.pkl')\n",
    "\n",
    "if not os.path.isfile(data_path):\n",
    "    start_date = datetime.strptime('2022-01-01',\"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime('2022-02-01',\"%Y-%m-%d\")\n",
    "    \n",
    "    data = get_comments(start_date, end_date) \n",
    "    \n",
    "    pickling_on = open(data_path,\"wb\")\n",
    "    pickle.dump(data, pickling_on)\n",
    "    pickling_on.close()\n",
    "    print('data pickled successfully!')\n",
    "else:\n",
    "    pickle_off = open(data_path, 'rb')\n",
    "    data = pickle.load(pickle_off)\n",
    "    print('data unpickled successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f82c99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18360c3b",
   "metadata": {},
   "source": [
    "## Preprocess textual data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03a47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate comments from ratings\n",
    "pos_text = []\n",
    "pos_cat = {}\n",
    "neg_text = []\n",
    "neg_cat = {}\n",
    "\n",
    "for review in data:\n",
    "    pos_text.append(review[0][0])\n",
    "    \n",
    "    for cat in review[0][1]:\n",
    "        if cat not in pos_cat.keys():\n",
    "            pos_cat[cat] = 1\n",
    "        else:\n",
    "            pos_cat[cat] += 1\n",
    "        \n",
    "    neg_text.append(review[1][0])\n",
    "    \n",
    "    for cat in review[1][1]:\n",
    "        if cat not in neg_cat.keys():\n",
    "            neg_cat[cat] = 1\n",
    "        else:\n",
    "            neg_cat[cat] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc6b2c",
   "metadata": {},
   "source": [
    "## Rating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4616e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.Series(pos_cat, name = 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4282708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.Series(neg_cat, name = 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e18e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(pos,neg, right_index = True, left_index = True, how='outer').sort_values('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb5d021-6bb6-41fd-a675-414d461d4188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Career Growth</th>\n",
       "      <td>288</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Satisfaction</th>\n",
       "      <td>297</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Security</th>\n",
       "      <td>324</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skill Development</th>\n",
       "      <td>325</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work-Life Balance</th>\n",
       "      <td>326</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary &amp; Benefits</th>\n",
       "      <td>351</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company Culture</th>\n",
       "      <td>382</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pos  neg\n",
       "Career Growth      288   83\n",
       "Work Satisfaction  297   80\n",
       "Job Security       324   63\n",
       "Skill Development  325   66\n",
       "Work-Life Balance  326   62\n",
       "Salary & Benefits  351   50\n",
       "Company Culture    382   35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec9331",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe66b03",
   "metadata": {},
   "source": [
    "### Positive comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6709dd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Everything work culture, seniors they are very supportive and superb is the word to describe this company.',\n",
       " 'Work Life balance and career growth ',\n",
       " 'Good company for skill development',\n",
       " 'Great company, terrible process',\n",
       " 'Work life balance and work culture is something which I love the most.',\n",
       " \"Amazon is a good company to work.But ML data associate role is not much intresting to work for. Very boaring job..no growth no skills. Don't apply for it.\",\n",
       " 'Work culture ',\n",
       " '01',\n",
       " 'Work Culture',\n",
       " 'Work is amazing. Volume of work is so much that you can have 4x experience when compared to other places. You can not sit and time pass without adding value.',\n",
       " 'Good work environment and culture. Teammates are supportive and the management is transparent. Everyone is happy to connect with you and share their experiences and help you in your career.',\n",
       " 'Everything is great about this company! ',\n",
       " 'Iam very intrested to work in it coustmer service. ',\n",
       " 'Management',\n",
       " 'I can handling cashier',\n",
       " 'I would love to work in a co operative environment and YES Amazon is very co operative and constructive. I feel very lucky to start my carrier with Amazon and yes I will look forward for any kind of work from Amazon. Overall I loved working at AMAZON!!',\n",
       " 'I am very happy to be worked on Amazon. The work is good and company pays the salary correctly\\r\\nI learnt a lot on Amazon',\n",
       " 'Salary',\n",
       " 'Nothing',\n",
       " 'There is a very piece of maind during work period, ',\n",
       " 'Work culture',\n",
       " 'Working environment for good and management was good supporting',\n",
       " 'Compensation, Technology industry',\n",
       " 'Good work environment. Company police are give good salary hoke and bonus every year',\n",
       " 'The culture',\n",
       " 'I really like the work culture ',\n",
       " \"It's always being a wonderful place to start our career as a fresher ,and work culture is so nice,job security also depends the way of learning, management is transparent.\",\n",
       " 'Internal movements and Every hour will be calculated and paid.',\n",
       " 'Prioriries',\n",
       " 'Amazon is a excellent process and company i really liked to work with this company. If I will get chance in future to work with this company i will definitely go with that ',\n",
       " 'Good work environment and culture.',\n",
       " 'Customer service..',\n",
       " 'Security, culture.',\n",
       " \"It's very good company and best policy this job\",\n",
       " 'Data analysis',\n",
       " 'Godd systematic job  way of the job',\n",
       " 'Best company , good atmosphere, good team members',\n",
       " 'Amazon good work environment and culture. Amazon team are supportive and management is transparent. Amazon is a good salary like and bonus every year.',\n",
       " 'Good thing about Amazon is continuous learning and career achievements and I hope everyday I learn and grow.',\n",
       " 'Environment is best.. leadership are very supportive. Friendly environment guys this is the most convenient place if you are looking forward to Amazon.. no doubt amazing work place']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore textual data\n",
    "pos_text[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4030219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fd0156c5e80>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fd0156c5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fd0159999e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fd0156c0c00>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fd0156c3640>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fd015999970>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load nlp pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58116e4a-b31e-4aea-98db-2ed1c6bbe9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fd0156c5e80>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fd0156c5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fd0159999e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fd0156c0c00>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fd0156c3640>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable NER component\n",
    "nlp.disable_pipe('ner')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5068b35-992c-455e-82fc-b9c9ddd5237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some stop words to improve analysis results\n",
    "nlp.Defaults.stop_words |= {'amazon','work','job','good'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af805bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts = []\n",
    "pos_texts_comment = []\n",
    "\n",
    "for comment in pos_text:\n",
    "    comment = nlp(comment)\n",
    "    text = []\n",
    "    for word in comment:\n",
    "        # Exclude special characters, stopwords, punctuations and numbers\n",
    "        if len(word.text.replace(\" \", \"\")) != 0 and word.text.replace(\" \", \"\")[0] != \"\\r\" and not word.is_stop\\\n",
    "        and not word.is_punct and not word.like_num:\n",
    "            text.append(word.lemma_.lower().replace(\" \", \"\"))\n",
    "        \n",
    "    if len(text) > 0:\n",
    "        pos_texts.append(text)\n",
    "        pos_texts_comment.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aefb6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['culture', 'senior', 'supportive', 'superb', 'word', 'describe', 'company'],\n",
       " ['life', 'balance', 'career', 'growth'],\n",
       " ['company', 'skill', 'development'],\n",
       " ['great', 'company', 'terrible', 'process'],\n",
       " ['life', 'balance', 'culture', 'love'],\n",
       " ['company',\n",
       "  'ml',\n",
       "  'data',\n",
       "  'associate',\n",
       "  'role',\n",
       "  'intreste',\n",
       "  'boaring',\n",
       "  'growth',\n",
       "  'skill',\n",
       "  'apply'],\n",
       " ['culture'],\n",
       " ['culture'],\n",
       " ['amazing',\n",
       "  'volume',\n",
       "  '4x',\n",
       "  'experience',\n",
       "  'compare',\n",
       "  'place',\n",
       "  'sit',\n",
       "  'time',\n",
       "  'pass',\n",
       "  'add',\n",
       "  'value'],\n",
       " ['environment',\n",
       "  'culture',\n",
       "  'teammate',\n",
       "  'supportive',\n",
       "  'management',\n",
       "  'transparent',\n",
       "  'happy',\n",
       "  'connect',\n",
       "  'share',\n",
       "  'experience',\n",
       "  'help',\n",
       "  'career'],\n",
       " ['great', 'company'],\n",
       " ['iam', 'intreste', 'coustmer', 'service'],\n",
       " ['management'],\n",
       " ['handle', 'cashier'],\n",
       " ['love',\n",
       "  'co',\n",
       "  'operative',\n",
       "  'environment',\n",
       "  'yes',\n",
       "  'co',\n",
       "  'operative',\n",
       "  'constructive',\n",
       "  'feel',\n",
       "  'lucky',\n",
       "  'start',\n",
       "  'carrier',\n",
       "  'yes',\n",
       "  'look',\n",
       "  'forward',\n",
       "  'kind',\n",
       "  'overall',\n",
       "  'love',\n",
       "  'work'],\n",
       " ['happy', 'work', 'company', 'pay', 'salary', 'correctly', 'learn', 'lot'],\n",
       " ['salary'],\n",
       " ['piece', 'maind', 'period'],\n",
       " ['culture'],\n",
       " ['working', 'environment', 'management', 'support'],\n",
       " ['compensation', 'technology', 'industry'],\n",
       " ['environment', 'company', 'police', 'salary', 'hoke', 'bonus', 'year'],\n",
       " ['culture'],\n",
       " ['like', 'culture'],\n",
       " ['wonderful',\n",
       "  'place',\n",
       "  'start',\n",
       "  'career',\n",
       "  'fresher',\n",
       "  'culture',\n",
       "  'nice',\n",
       "  'security',\n",
       "  'depend',\n",
       "  'way',\n",
       "  'learning',\n",
       "  'management',\n",
       "  'transparent'],\n",
       " ['internal', 'movement', 'hour', 'calculate', 'pay'],\n",
       " ['prioririe'],\n",
       " ['excellent',\n",
       "  'process',\n",
       "  'company',\n",
       "  'like',\n",
       "  'company',\n",
       "  'chance',\n",
       "  'future',\n",
       "  'company',\n",
       "  'definitely'],\n",
       " ['environment', 'culture'],\n",
       " ['customer', 'service'],\n",
       " ['security', 'culture'],\n",
       " ['company', 'good', 'policy'],\n",
       " ['data', 'analysis'],\n",
       " ['godd', 'systematic', 'way'],\n",
       " ['good', 'company', 'atmosphere', 'team', 'member'],\n",
       " ['environment',\n",
       "  'culture',\n",
       "  'team',\n",
       "  'supportive',\n",
       "  'management',\n",
       "  'transparent',\n",
       "  'salary',\n",
       "  'like',\n",
       "  'bonus',\n",
       "  'year'],\n",
       " ['thing',\n",
       "  'continuous',\n",
       "  'learning',\n",
       "  'career',\n",
       "  'achievement',\n",
       "  'hope',\n",
       "  'everyday',\n",
       "  'learn',\n",
       "  'grow'],\n",
       " ['environment',\n",
       "  'good',\n",
       "  'leadership',\n",
       "  'supportive',\n",
       "  'friendly',\n",
       "  'environment',\n",
       "  'guy',\n",
       "  'convenient',\n",
       "  'place',\n",
       "  'look',\n",
       "  'forward',\n",
       "  'doubt',\n",
       "  'amazing',\n",
       "  'place'],\n",
       " ['security'],\n",
       " ['shifiting', 'salary', 'friend']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore processed data\n",
    "pos_texts[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b9d7178-1798-480e-aafd-110f62de721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams, dictionary and corpus\n",
    "pos_bigram = Phrases(pos_texts, min_count=1, threshold=2, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "pos_texts = [pos_bigram[line] for line in pos_texts]\n",
    "pos_dictionary = Dictionary(pos_texts)\n",
    "pos_corpus = [pos_dictionary.doc2bow(text) for text in pos_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22643c8",
   "metadata": {},
   "source": [
    "### Negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181aca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_texts = []\n",
    "neg_texts_comment = []\n",
    "\n",
    "for comment in neg_text:\n",
    "    comment = nlp(comment)\n",
    "    text = []\n",
    "    for word in comment:\n",
    "        # Exclude special characters, stopwords, punctuations and numbers\n",
    "        if len(word.text.replace(\" \", \"\")) != 0 and word.text.replace(\" \", \"\")[0] != \"\\r\" and not word.is_stop\\\n",
    "        and not word.is_punct and not word.like_num:\n",
    "            text.append(word.lemma_.lower().replace(\" \", \"\"))\n",
    "        \n",
    "    if len(text) > 0:\n",
    "        neg_texts.append(text)\n",
    "        neg_texts_comment.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eeef9ae-d032-4e6b-b1f1-d54bac72f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams, dictionary and corpus\n",
    "neg_bigram = Phrases(neg_texts, min_count=1, threshold=2, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "neg_texts = [neg_bigram[line] for line in neg_texts]\n",
    "neg_dictionary = Dictionary(neg_texts)\n",
    "neg_corpus = [neg_dictionary.doc2bow(text) for text in neg_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42da51-6be1-4680-badb-fa897bec5f3b",
   "metadata": {},
   "source": [
    "### Pickle everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed374e95-82ec-4df6-b708-ff7c5c5ad304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data pickled successfully!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.environ['PWD'],'data/january_comments_processed.pkl')\n",
    "\n",
    "if not os.path.isfile(data_path):\n",
    "    data = {}\n",
    "    data['ratings'] = ratings\n",
    "    \n",
    "    data['pos_texts'] = pos_texts\n",
    "    data['pos_dictionary'] = pos_dictionary\n",
    "    data['pos_corpus'] = pos_corpus\n",
    "    data['pos_texts_comment'] = pos_texts_comment\n",
    "    \n",
    "    data['neg_texts'] = neg_texts\n",
    "    data['neg_dictionary'] = neg_dictionary\n",
    "    data['neg_corpus'] = neg_corpus\n",
    "    data['neg_texts_comment'] = neg_texts_comment\n",
    "    \n",
    "    pickling_on = open(data_path,\"wb\")\n",
    "    pickle.dump(data, pickling_on)\n",
    "    pickling_on.close()\n",
    "    print('data pickled successfully!')\n",
    "else:\n",
    "    pickle_off = open(data_path, 'rb')\n",
    "    data = pickle.load(pickle_off)\n",
    "    print('data unpickled successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde365c0-e679-42ac-a2a4-dd17e53fa202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
